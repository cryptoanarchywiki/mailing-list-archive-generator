---
layout: default
---

# 1997-09-27 - Re: Remailer latencies (fwd)

## Header Data

From: "Brian B. Riley" \<brianbr<span>@</span>together.net\><br>
To: "Cypherpunks Distributed Remailer" \<cypherpunks@ssz.com\><br>
Message Hash: af03d3650062eec4bd67fbb3634ecd71387e8e9863afa14b9d2b2c2174903d4a<br>
Message ID: \<199709271417.KAA14041@mx02.together.net\><br>
Reply To: _N/A_<br>
UTC Datetime: 1997-09-27 14:36:36 UTC<br>
Raw Date: Sat, 27 Sep 1997 22:36:36 +0800<br>

## Raw message

```
{% raw  %}From: "Brian B. Riley" <brianbr@together.net>
Date: Sat, 27 Sep 1997 22:36:36 +0800
To: "Cypherpunks Distributed Remailer" <cypherpunks@ssz.com>
Subject: Re: Remailer latencies (fwd)
Message-ID: <199709271417.KAA14041@mx02.together.net>
MIME-Version: 1.0
Content-Type: text/plain



-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 9/26/97 11:49 PM, Jim Choate (ravage@ssz.com)  passed this wisdom:

>> And, since you asked, would it not be in the interests of remailer
>> operators to have a script which would generate random text,
encrypt
>> it to various remailers and send it out as 'cover traffic'?
>> It would seem to me that this would be particularly valuable for
the
>> remailers that receive the least amount of traffic.
>
>This aspect of traffic cover is more complex than it at first 
>seems. Take for example the second simplest model that I am aware 
>of. For each email that comes in n bogus emails go out with one 
>remailed copy. So for each email we receive we end up processing 
>n+2 emails. Since to be useful n must be reasonably larger than 2 
>to be effective we are left with a quandry. Aswe process more 
>traffic (ie become successful) we find our bandwidth need growing 
>at a linear rate of n, unfortunately the skills and resources to 
>support this increase also get larger as we become more successful. 

 I am incline to think that as the traffic goes up the need to
generate 'n' mails for each 'real' inbound/outbound goes down.  It
would seem to me that one could specify a general volume level, ie, in
a given period of time, say 1 hour if only 1-20 objects of mail comes
in, generate some random amount between say 20 and 100 bogus objects
to have a volume level that provides the uncertainty to
foil/complicate traffic analysis. If 20 to 40 real mails come in,
generate 30 to 150 objects, if 40 to 100 comes in maybe only 40 to 200
extra objects. As the volume rises, it seems to be the need for
voluminous additional bogus objects decreases somewhat as you have
plenty of objects to get a good 'mix' and 'latency.'

  I will admit I am a neophyte here and am working more on what
appears to me as common sense; I would be happy to be educated as to
what is wrong with the above logic ...

-----BEGIN PGP SIGNATURE-----
Version: PGP for Personal Privacy 5.0
Charset: noconv

iQA/AwUBNC0UPsdZgC62U/gIEQKBXgCfZIXbYvWRz2dyGknCt8YXw6Uz+2IAnjO0
4Qf0UZLqODa4GYioABPAPjcf
=CUL5
-----END PGP SIGNATURE-----


Brian B. Riley --> http://www.macconnect.com/~brianbr
  For PGP Keys  <mailto:brianbr@together.net?subject=Get%20PGP%20Key>

 "I left him for dead and buried his axe.  If there was a Valhalla, I
  wanted him weaponless." from "Highlander"






{% endraw %}
```

## Thread

+ Return to [September 1997](/archive/1997/09)

+ Return to "["Brian B. Riley" <brianbr<span>@</span>together.net>](/author/brian_b_riley_brianbr_at_together_net_)"

+ 1997-09-27 (Sat, 27 Sep 1997 22:36:36 +0800) - Re: Remailer latencies (fwd) - _"Brian B. Riley" \<brianbr@together.net\>_

