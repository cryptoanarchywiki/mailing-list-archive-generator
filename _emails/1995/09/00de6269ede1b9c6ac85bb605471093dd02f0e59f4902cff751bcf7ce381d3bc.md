---
layout: default
---

# 1995-09-25 - RE: More on "Entropy"

## Header Data

From: David Van Wie \<dvw<span>@</span>hamachi.epr.com\><br>
To: "Timothy C. May" \<tcmay@got.net\><br>
Message Hash: 00de6269ede1b9c6ac85bb605471093dd02f0e59f4902cff751bcf7ce381d3bc<br>
Message ID: \<30673C18@hamachi\><br>
Reply To: _N/A_<br>
UTC Datetime: 1995-09-25 23:35:08 UTC<br>
Raw Date: Mon, 25 Sep 95 16:35:08 PDT<br>

## Raw message

```
{% raw  %}From: David Van Wie <dvw@hamachi.epr.com>
Date: Mon, 25 Sep 95 16:35:08 PDT
To: "Timothy C. May" <tcmay@got.net>
Subject: RE: More on "Entropy"
Message-ID: <30673C18@hamachi>
MIME-Version: 1.0
Content-Type: text/plain



David Van Wie wrote:

>>The entropy E is defined by the sum across n states of -P_i log_2(P_i),

Timothy C. May wrote:

>Hah! Another physicist converted to the information-theoretic view of 
entropy!

Indeed.  I was able to track down the literature, and it is most 
interesting.  I am still a little bit skeptical of the "superset including 
thermodynamic entropy" school of thought, but I haven't finished reading all 
of the materials yet!  Clearly, the IT "version" of entropy is a well 
defined and useful thing....

>I should've pointed out in my reading list that several names stand out in
>this interpretation:

I'll read with that endoresement in mind.  Your thoughts on rigorous, 
_concise_, design criteria for sources of entropy would be appreciated 
(unless there is good quality work in the literature I haven't come to yet).

dvw




{% endraw %}
```

## Thread

+ Return to [September 1995](/archive/1995/09)

+ Return to "[David Van Wie <dvw<span>@</span>hamachi.epr.com>](/authors/david_van_wie_dvw_at_hamachi_epr_com_)"

+ 1995-09-25 (Mon, 25 Sep 95 16:35:08 PDT) - RE: More on "Entropy" - _David Van Wie \<dvw@hamachi.epr.com\>_

