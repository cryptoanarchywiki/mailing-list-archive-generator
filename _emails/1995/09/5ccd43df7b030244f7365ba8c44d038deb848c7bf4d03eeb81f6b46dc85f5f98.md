---
layout: default
---

# 1995-09-26 - RE: More on "Entropy"

## Header Data

From: David Van Wie \<dvw<span>@</span>hamachi.epr.com\><br>
To: "'cypherpunks'" \<cypherpunks@toad.com\><br>
Message Hash: 5ccd43df7b030244f7365ba8c44d038deb848c7bf4d03eeb81f6b46dc85f5f98<br>
Message ID: \<30687699@hamachi\><br>
Reply To: _N/A_<br>
UTC Datetime: 1995-09-26 21:56:30 UTC<br>
Raw Date: Tue, 26 Sep 95 14:56:30 PDT<br>

## Raw message

```
{% raw  %}From: David Van Wie <dvw@hamachi.epr.com>
Date: Tue, 26 Sep 95 14:56:30 PDT
To: "'cypherpunks'" <cypherpunks@toad.com>
Subject: RE: More on "Entropy"
Message-ID: <30687699@hamachi>
MIME-Version: 1.0
Content-Type: text/plain



David Van Wie wrote:

>>The entropy E is defined by the sum across n states of -P_i log_2(P_i),

Timothy C. May wrote:

>Hah! Another physicist converted to the information-theoretic view of 
entropy!

Indeed.  I was able to track down the literature, and it is most 
interesting.  I am still a little bit skeptical of the "superset including 
thermodynamic entropy" school of thought, but I haven't finished reading all 
of the materials yet!  Clearly, the IT "version" of entropy is a well 
defined and useful thing....

>I should've pointed out in my reading list that several names stand out in
>this interpretation:

I'll read with that endoresement in mind.  Your thoughts on rigorous, 
_concise_, design criteria for sources of entropy would be appreciated 
(unless there is good quality work in the literature I haven't come to yet).

dvw




{% endraw %}
```

## Thread

+ Return to [September 1995](/archive/1995/09)

+ Return to "[David Van Wie <dvw<span>@</span>hamachi.epr.com>](/author/david_van_wie_dvw_at_hamachi_epr_com_)"

+ 1995-09-26 (Tue, 26 Sep 95 14:56:30 PDT) - RE: More on "Entropy" - _David Van Wie \<dvw@hamachi.epr.com\>_

