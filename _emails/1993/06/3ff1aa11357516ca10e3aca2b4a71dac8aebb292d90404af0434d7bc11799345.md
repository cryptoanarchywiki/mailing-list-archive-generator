---
layout: default
---

# 1993-06-01 - Re: Verifying Privacy as an Upload/AI?

## Header Data

From: peb@PROCASE.COM<br>
To: fnerd@smds.com<br>
Message Hash: 3ff1aa11357516ca10e3aca2b4a71dac8aebb292d90404af0434d7bc11799345<br>
Message ID: \<9306012209.AA17679@banff.procase.com\><br>
Reply To: _N/A_<br>
UTC Datetime: 1993-06-01 21:32:55 UTC<br>
Raw Date: Tue, 1 Jun 93 14:32:55 PDT<br>

## Raw message

```
{% raw  %}From: peb@PROCASE.COM
Date: Tue, 1 Jun 93 14:32:55 PDT
To: fnerd@smds.com
Subject: Re: Verifying Privacy as an Upload/AI?
Message-ID: <9306012209.AA17679@banff.procase.com>
MIME-Version: 1.0
Content-Type: text/plain



I think you are headed in the right direction wrt a capability system, 
however, they are predicated on tamper proof hardware.  Since you 
stipulate human being copying and torturing (sounds like tampering
to me), I think this is not ultimate privacy.

Hmm, perhaps you should set up a key escrow system (!) so that you need
to call your most trusted friends to assemble your session key.  The
session key works only once, assuming a tamper proof, capability system.
When you call them, they can quiz you on your mental and physical health
to determine whether they should give you the keys...thus limiting the 
ability of a torturer.

Paul E. Baclace
peb@procase.com





{% endraw %}
```

## Thread

+ Return to [June 1993](/archive/1993/06)

+ 1993-06-01 (Tue, 1 Jun 93 14:32:55 PDT) - Re: Verifying Privacy as an Upload/AI? - _peb@PROCASE.COM_
  + 1993-06-01 (Tue, 1 Jun 93 15:06:14 PDT) - [Re: Verifying Privacy as an Upload/AI?](/archive/1993/06/28a10857540a03f626dba9a52065187c8b6e839b54bac100b0d9e5db3b5b9ec2) - _Marc Horowitz \<marc@GZA.COM\>_

