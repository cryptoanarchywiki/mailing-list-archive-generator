---
layout: default
---

# 1994-07-16 - Factoring

## Header Data

From: hughes@ah.com (Eric Hughes)<br>
To: cypherpunks@toad.com<br>
Message Hash: 14d6d66f6811c4819870f91ab0284c850c82fc55ab46ca279903fdb1851ec244<br>
Message ID: \<9407161648.AA19160@ah.com\><br>
Reply To: \<199407152358.TAA08861@bb.com\><br>
UTC Datetime: 1994-07-16 17:13:10 UTC<br>
Raw Date: Sat, 16 Jul 94 10:13:10 PDT<br>

## Raw message

```
{% raw  %}From: hughes@ah.com (Eric Hughes)
Date: Sat, 16 Jul 94 10:13:10 PDT
To: cypherpunks@toad.com
Subject: Factoring
In-Reply-To: <199407152358.TAA08861@bb.com>
Message-ID: <9407161648.AA19160@ah.com>
MIME-Version: 1.0
Content-Type: text/plain


   > When discussing complexity it is usual to use a measure of problem
   > size that corresponds to the physical size of the answer or
   > the question.

Not quite.  The length of the answer is not typically used in measures
of complexity.

The 'n' in O(n^2), et al., is the length of the input.  Exactly that,
and nothing more.  The length used is the number of symbols used to
encode the input from some finite alphabet of symbols.  Thus, the
lengths are determined up to a constant factor related to the
logarithm of the size of the alphabet.

   > Thus thus if you are factoring a 1024 bit number, n is 1024, not
   > 2^1024

Yes.  Getting the wrong 'n' will make complexity theory meaningless
and impenetrable.

Eric




{% endraw %}
```

## Thread

+ Return to [July 1994](/archive/1994/07)

+ 1994-07-15 (Fri, 15 Jul 94 16:56:54 PDT) - [Factoring](/archive/1994/07/53bd8d25e731f11532ce57483ca9022cedacc3c3b1cab11e6658159638b89d03) - _"L. Todd Masco" \<cactus@bb.com\>_
  + 1994-07-16 (Sat, 16 Jul 94 10:13:10 PDT) - Factoring - _hughes@ah.com (Eric Hughes)_

