---
layout: default
---

# 1996-04-08 - Re: Spinners and compression functions

## Header Data

From: "Perry E. Metzger" \<perry@piermont.com\><br>
To: JonWienke@aol.com<br>
Message Hash: 5b6df299831b19e4d7d5e6280d3cef014c65180e53fa9abd8621b9bcbffdf3c9<br>
Message ID: \<199604072252.SAA29569@jekyll.piermont.com\><br>
Reply To: _N/A_<br>
UTC Datetime: 1996-04-08 03:54:03 UTC<br>
Raw Date: Mon, 8 Apr 1996 11:54:03 +0800<br>

## Raw message

```
{% raw  %}From: "Perry E. Metzger" <perry@piermont.com>
Date: Mon, 8 Apr 1996 11:54:03 +0800
To: JonWienke@aol.com
Subject: Re: Spinners and compression functions
Message-ID: <199604072252.SAA29569@jekyll.piermont.com>
MIME-Version: 1.0
Content-Type: text/plain



[I've sent a fuller reply to Jon in private mail.]

JonWienke@aol.com writes:
> >Actually, it doesn't. The entropy present from a reasonable source
> >like keyclick timings is much much lower than the output of pkzip is
> >going to suggest to you.
> 
> I am not saying that the output of the compression function has 8 bits of
> entropy per byte, but rather that it will have a more consistent entropy
> level per byte than the input to the function.

What makes you think that? There is little to no cause to expect this
at all. I can think of a number of instances, like image data streams,
where this idea is completely unfounded for most conventional
compression techniques.

Perry




{% endraw %}
```

## Thread

+ Return to [April 1996](/archive/1996/04)

+ 1996-04-08 (Mon, 8 Apr 1996 11:54:03 +0800) - Re: Spinners and compression functions - _"Perry E. Metzger" \<perry@piermont.com\>_

