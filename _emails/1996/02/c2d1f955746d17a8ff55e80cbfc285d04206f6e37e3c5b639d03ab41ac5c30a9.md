---
layout: default
---

# 1996-02-22 - Re: Internet Privacy Guaranteed ad (POTP Jr.)

## Header Data

From: "Perry E. Metzger" \<perry<span>@</span>piermont.com\><br>
To: IPG Sales \<ipgsales@cyberstation.net\><br>
Message Hash: c2d1f955746d17a8ff55e80cbfc285d04206f6e37e3c5b639d03ab41ac5c30a9<br>
Message ID: \<199602212043.PAA10048@jekyll.piermont.com\><br>
Reply To: \<Pine.BSD/.3.91.960221132344.3814A-100000@citrine.cyberstation.net\><br>
UTC Datetime: 1996-02-22 00:31:58 UTC<br>
Raw Date: Thu, 22 Feb 1996 08:31:58 +0800<br>

## Raw message

```
{% raw  %}From: "Perry E. Metzger" <perry@piermont.com>
Date: Thu, 22 Feb 1996 08:31:58 +0800
To: IPG Sales <ipgsales@cyberstation.net>
Subject: Re: Internet Privacy Guaranteed ad (POTP Jr.)
In-Reply-To: <Pine.BSD/.3.91.960221132344.3814A-100000@citrine.cyberstation.net>
Message-ID: <199602212043.PAA10048@jekyll.piermont.com>
MIME-Version: 1.0
Content-Type: text/plain



IPG Sales writes:
> Stubborness and stupidity are twins - Sophocles

IPG is both stubborn and stupid. How appropriate.

Let me give you another quote. It is acually a long extract of a
document written by Phil Zimmermann. Read it.

    Beware of Snake Oil
    ===================
    
    When examining a cryptographic software package, the question always
    remains, why should you trust this product?  Even if you examined the
    source code yourself, not everyone has the cryptographic experience
    to judge the security.  Even if you are an experienced cryptographer,
    subtle weaknesses in the algorithms could still elude you. 
    
    When I was in college in the early seventies, I devised what I
    believed was a brilliant encryption scheme.  A simple pseudorandom
    number stream was added to the plaintext stream to create
    ciphertext.  This would seemingly thwart any frequency analysis of
    the ciphertext, and would be uncrackable even to the most resourceful
    Government intelligence agencies.  I felt so smug about my
    achievement.  So cock-sure.  
    
    Years later, I discovered this same scheme in several introductory
    cryptography texts and tutorial papers.  How nice.  Other
    cryptographers had thought of the same scheme.  Unfortunately, the
    scheme was presented as a simple homework assignment on how to use
    elementary cryptanalytic techniques to trivially crack it.  So much
    for my brilliant scheme.
    
    From this humbling experience I learned how easy it is to fall into a
    false sense of security when devising an encryption algorithm.  Most
    people don't realize how fiendishly difficult it is to devise an
    encryption algorithm that can withstand a prolonged and determined
    attack by a resourceful opponent.  Many mainstream software engineers
    have developed equally naive encryption schemes (often even the very
    same encryption scheme), and some of them have been incorporated into
    commercial encryption software packages and sold for good money to
    thousands of unsuspecting users. 
    
    This is like selling automotive seat belts that look good and feel
    good, but snap open in even the slowest crash test.  Depending on
    them may be worse than not wearing seat belts at all.  No one
    suspects they are bad until a real crash.  Depending on weak
    cryptographic software may cause you to unknowingly place sensitive
    information at risk.  You might not otherwise have done so if you had
    no cryptographic software at all.  Perhaps you may never even
    discover your data has been compromised.
    
    Sometimes commercial packages use the Federal Data Encryption
    Standard (DES), a fairly good conventional algorithm recommended by
    the Government for commercial use (but not for classified
    information, oddly enough-- hmmm).  There are several "modes of
    operation" the DES can use, some of them better than others.  The
    Government specifically recommends not using the weakest simplest
    mode for messages, the Electronic Codebook (ECB) mode.  But they do
    recommend the stronger and more complex Cipher Feedback (CFB) or
    Cipher Block Chaining (CBC) modes.  
    
    Unfortunately, most of the commercial encryption packages I've looked
    at use ECB mode.  When I've talked to the authors of a number of
    these implementations, they say they've never heard of CBC or CFB
    modes, and didn't know anything about the weaknesses of ECB mode. 
    The very fact that they haven't even learned enough cryptography to
    know these elementary concepts is not reassuring.  And they sometimes
    manage their DES keys in inappropriate or insecure ways.  Also, these
    same software packages often include a second faster encryption
    algorithm that can be used instead of the slower DES.  The author of
    the package often thinks his proprietary faster algorithm is as
    secure as the DES, but after questioning him I usually discover that
    it's just a variation of my own brilliant scheme from college days. 
    Or maybe he won't even reveal how his proprietary encryption scheme
    works, but assures me it's a brilliant scheme and I should trust it. 
    I'm sure he believes that his algorithm is brilliant, but how can I
    know that without seeing it?  
    
    In all fairness I must point out that in most cases these terribly
    weak products do not come from companies that specialize in
    cryptographic technology.
    
    Even the really good software packages, that use the DES in the
    correct modes of operation, still have problems.  Standard DES uses a
    56-bit key, which is too small by today's standards, and may now be
    easily broken by exhaustive key searches on special high-speed
    machines.  The DES has reached the end of its useful life, and so has
    any software package that relies on it.
    
    There is a company called AccessData (87 East 600 South, Orem, Utah
    84058, phone 1-800-658-5199) that sells a package for $185 that
    cracks the built-in encryption schemes used by WordPerfect, Lotus
    1-2-3, MS Excel, Symphony, Quattro Pro, Paradox, and MS Word 2.0.  It
    doesn't simply guess passwords-- it does real cryptanalysis.  Some
    people buy it when they forget their password for their own files. 
    Law enforcement agencies buy it too, so they can read files they
    seize.  I talked to Eric Thompson, the author, and he said his
    program only takes a split second to crack them, but he put in some
    delay loops to slow it down so it doesn't look so easy to the
    customer.  He also told me that the password encryption feature of
    PKZIP files can often be easily broken, and that his law enforcement
    customers already have that service regularly provided to them from
    another vendor. 
    
    In some ways, cryptography is like pharmaceuticals.  Its integrity
    may be absolutely crucial.  Bad penicillin looks the same as good
    penicillin.  You can tell if your spreadsheet software is wrong, but
    how do you tell if your cryptography package is weak?  The ciphertext
    produced by a weak encryption algorithm looks as good as ciphertext
    produced by a strong encryption algorithm.  There's a lot of snake
    oil out there.  A lot of quack cures.  Unlike the patent medicine
    hucksters of old, these software implementors usually don't even know
    their stuff is snake oil.  They may be good software engineers, but 
    they usually haven't even read any of the academic literature in
    cryptography.  But they think they can write good cryptographic
    software.  And why not?  After all, it seems intuitively easy to do
    so.  And their software seems to work okay.    
    
    Anyone who thinks they have devised an unbreakable encryption scheme
    either is an incredibly rare genius or is naive and inexperienced. 
    Unfortunately, I sometimes have to deal with would-be cryptographers
    who want to make "improvements" to PGP by adding encryption
    algorithms of their own design.
    
    I remember a conversation with Brian Snow, a highly placed senior
    cryptographer with the NSA.  He said he would never trust an
    encryption algorithm designed by someone who had not "earned their
    bones" by first spending a lot of time cracking codes.  That did make
    a lot of sense.  I observed that practically no one in the commercial
    world of cryptography qualified under this criterion.  "Yes", he said
    with a self assured smile, "And that makes our job at NSA so much
    easier."  A chilling thought.  I didn't qualify either.
    
    The Government has peddled snake oil too.  After World War II, the US
    sold German Enigma ciphering machines to third world governments.
    But they didn't tell them that the Allies cracked the Enigma code
    during the war, a fact that remained classified for many years.  Even
    today many Unix systems worldwide use the Enigma cipher for file
    encryption, in part because the Government has created legal
    obstacles against using better algorithms.  They even tried to
    prevent the initial publication of the RSA algorithm in 1977.  And
    they have squashed essentially all commercial efforts to develop
    effective secure telephones for the general public. 
    
    The principal job of the US Government's National Security Agency is
    to gather intelligence, principally by covertly tapping into people's
    private communications (see James Bamford's book, "The Puzzle
    Palace").  The NSA has amassed considerable skill and resources for
    cracking codes.  When people can't get good cryptography to protect
    themselves, it makes NSA's job much easier.  NSA also has the
    responsibility of approving and recommending encryption algorithms. 
    Some critics charge that this is a conflict of interest, like putting
    the fox in charge of guarding the hen house.  NSA has been pushing a
    conventional encryption algorithm that they designed, and they won't
    tell anybody how it works because that's classified.  They want
    others to trust it and use it.  But any cryptographer can tell you
    that a well-designed encryption algorithm does not have to be
    classified to remain secure.  Only the keys should need protection. 
    How does anyone else really know if NSA's classified algorithm is
    secure?  It's not that hard for NSA to design an encryption algorithm
    that only they can crack, if no one else can review the algorithm. 
    Are they deliberately selling snake oil? 
    
    There are three main factors that have undermined the quality of
    commercial cryptographic software in the US.  The first is the
    virtually universal lack of competence of implementors of commercial
    encryption software (although this is starting to change since the
    publication of PGP).  Every software engineer fancies himself a
    cryptographer, which has led to the proliferation of really bad
    crypto software.  The second is the NSA deliberately and
    systematically suppressing all the good commercial encryption
    technology, by legal intimidation and economic pressure.  Part of
    this pressure is brought to bear by stringent export controls on
    encryption software which, by the economics of software marketing,
    has the net effect of suppressing domestic encryption software.  The
    other principle method of suppression comes from the granting all the
    software patents for all the public key encryption algorithms to a
    single company, affording a single choke point to suppress the spread
    of this technology.  The net effect of all this is that before PGP
    was published, there was almost no highly secure general purpose
    encryption software available in the US.
    
    I'm not as certain about the security of PGP as I once was about my
    brilliant encryption software from college.  If I were, that would be
    a bad sign.  But I'm pretty sure that PGP does not contain any
    glaring weaknesses (although it may contain bugs).  The crypto
    algorithms were developed by people at high levels of civilian
    cryptographic academia, and have been individually subject to
    extensive peer review.  Source code is available to facilitate peer
    review of PGP and to help dispel the fears of some users.  It's
    reasonably well researched, and has been years in the making.  And I
    don't work for the NSA.  I hope it doesn't require too large a "leap
    of faith" to trust the security of PGP.
    
             -- Phil Zimmerman, in the PGP manual.


IPG Sales writes:
> 1. The OTPs are generated on a standalone diskette only system,

They are not One Time Pads. They are keys for a random number
generator. Your continued assertion that they are One Time Pads is
fraudulent. They are not one time pads by any definition ever
previously used.

Furthermore, as has been stated, it is completely unacceptable for
keys to be generated by third parties.

> 2. From there, they go to QC - we perform:

The QC you perform is irrelevant.

The system you sell is insecure in a practical sense, likely uses an
insecure PRNG, and uses names and makes claims that come very close to
being fraudlent. It is harder, not easier, to manage the keys from
your system that supposedly "eliminates key management", and you don't
even have any shame about the fact that you are ignorant of the field
you work in.

> Ralph 
    
Perry
    




{% endraw %}
```

## Thread

+ Return to [February 1996](/archive/1996/02)

+ Return to "[don<span>@</span>cs.byu.edu](/authors/don_at_cs_byu_edu)"
+ Return to "[Ed Carp <erc<span>@</span>dal1820.computek.net>](/authors/ed_carp_erc_at_dal1820_computek_net_)"
+ Return to "[IPG Sales <ipgsales<span>@</span>cyberstation.net>](/authors/ipg_sales_ipgsales_at_cyberstation_net_)"
+ Return to "[m5<span>@</span>dev.tivoli.com (Mike McNally)](/authors/m5_at_dev_tivoli_com_mike_mcnally_)"
+ Return to "["Perry E. Metzger" <perry<span>@</span>piermont.com>](/authors/perry_e_metzger_perry_at_piermont_com_)"
+ Return to "["Richard Martin" <rmartin<span>@</span>aw.sgi.com>](/authors/richard_martin_rmartin_at_aw_sgi_com_)"
+ Return to "[shamrock<span>@</span>netcom.com (Lucky Green)](/authors/shamrock_at_netcom_com_lucky_green_)"
+ Return to "[Sten Drescher <stend<span>@</span>grendel.texas.net>](/authors/sten_drescher_stend_at_grendel_texas_net_)"
+ Return to "[Tim Philp <bplib<span>@</span>wat.hookup.net>](/authors/tim_philp_bplib_at_wat_hookup_net_)"

+ 1996-02-21 (Wed, 21 Feb 1996 13:53:16 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/3eb6c7d2ebee47afee190ea8d50297570a0775fd106150fd6e5e14e3e8ef94dc) - _shamrock@netcom.com (Lucky Green)_
  + 1996-02-21 (Wed, 21 Feb 1996 13:45:34 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/af443f612b8bb40ec5b0adfeb341af30d60e8633b4d02d76d57ab0333bbc08f3) - _IPG Sales \<ipgsales@cyberstation.net\>_
    + 1996-02-21 (Tue, 20 Feb 96 20:55:41 PST) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/309cb3723070aa37e68a4f67617030de0acb92111fbe7904cf63549cd6804052) - _Tim Philp \<bplib@wat.hookup.net\>_
      + 1996-02-21 (Tue, 20 Feb 96 21:25:23 PST) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/24a6dac89d78050350af1dac56f6b93b291e92407e01f39b7e42deb402c675b1) - _Ed Carp \<erc@dal1820.computek.net\>_
      + 1996-02-21 (Thu, 22 Feb 1996 07:26:04 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/d205179546544be4b6e6ae155abdd62135e2366af787457b341f74917d4ba0a9) - _IPG Sales \<ipgsales@cyberstation.net\>_
        + 1996-02-22 (Thu, 22 Feb 1996 08:31:58 +0800) - Re: Internet Privacy Guaranteed ad (POTP Jr.) - _"Perry E. Metzger" \<perry@piermont.com\>_
  + 1996-02-21 (Wed, 21 Feb 1996 22:24:43 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/6daaec205ab11f68d740bd97da155191b9bb7a12e2b9bbd9d22bb71aec8a5cc3) - _m5@dev.tivoli.com (Mike McNally)_
    + 1996-02-21 (Thu, 22 Feb 1996 00:40:14 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/3efb615a54b09d17674445ed815f69404412592faaa4f3d9a6b1e42b2f226afe) - _"Perry E. Metzger" \<perry@piermont.com\>_
    + 1996-02-22 (Thu, 22 Feb 1996 09:08:50 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/127a1df6f6580ab13b9a638ce6989e9eac1360ad14a73ac89027a2164f1e84ce) - _IPG Sales \<ipgsales@cyberstation.net\>_
      + 1996-02-22 (Thu, 22 Feb 1996 20:03:14 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/b80dab6728d38fb2777c8fe0c690d32863297078b28876ef2dd6b236fd1b99e2) - _"Richard Martin" \<rmartin@aw.sgi.com\>_
      + 1996-02-23 (Fri, 23 Feb 1996 16:07:53 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/32e9deb8dc4bee044007d16e7a1ea33ede9e239bf32c169fdd32ebdaad91e70d) - _"Perry E. Metzger" \<perry@piermont.com\>_
    + 1996-02-22 (Thu, 22 Feb 1996 22:51:41 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/292fb3b088961778d1193de809e7a88b0e36ca8e410e6a7296a453274a247544) - _Sten Drescher \<stend@grendel.texas.net\>_
  + 1996-02-22 (Thu, 22 Feb 1996 08:20:46 +0800) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/be566ded192fa598d6349e8bb63deffdc75366f76620a924bd89cd51f08fb47b) - _IPG Sales \<ipgsales@cyberstation.net\>_
    + 1996-02-21 (Wed, 21 Feb 96 00:12:57 PST) - [Re: Internet Privacy Guaranteed ad (POTP Jr.)](/archive/1996/02/efefeee4c8062041621dea2f5ebee213d0cdd26a478c90ebb54c803c45d804fc) - _don@cs.byu.edu_

